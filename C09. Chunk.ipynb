{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chunking is a process of extracting phrases from unstructured text. Instead of just simple tokens which may not represent the actual meaning of the text, its advisable to use phrases such as “South Africa” as a single word instead of ‘South’ and ‘Africa’ separate words.\n",
    "\n",
    "Chunking works on top of POS tagging, it uses pos-tags as input and provides chunks as output. Similar to POS tags, there are a standard set of Chunk tags like Noun Phrase(NP), Verb Phrase (VP), etc. Chunking is very important when you want to extract information from text such as Locations, Person Names etc. In NLP called Named Entity Extraction.\n",
    "\n",
    "A chunk is a short phrase within a sentence.\n",
    "\n",
    "Text chunking, also referred to as shallow parsing, is a task that follows Part-Of-Speech Tagging and that adds more structure to the sentence. The result is a grouping of the words in “chunks”.\n",
    "\n",
    " These are patterns of part-of-speech tags that de ne what kinds of words make up a chunk. We can also de ne patterns for what kinds of words should not be in a chunk. These unchunked words are known as chinks.\n",
    "A ChunkRule class speci es what to include in a chunk, while a ChinkRule class speci es what to exclude from a chunk. In other words, chunking creates chunks, while chinking breaks up those chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prison riot\n",
      "members\n",
      "hospital treatment\n",
      "BBC\n",
      "learns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "\n",
    "def prepareForNLP(text):\n",
    "\tsentences = nltk.sent_tokenize(text)\n",
    "\tsentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\tsentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "\treturn sentences\n",
    "\n",
    "def chunk(sentence):\n",
    "\tchunkToExtract = \"\"\"\n",
    "\tNP: {<NNP>*}\n",
    "\t\t{<DT>?<JJ>?<NNS>}\n",
    "\t\t{<NN><NN>}\"\"\"\n",
    "\tparser = nltk.RegexpParser(chunkToExtract)\n",
    "\tresult = parser.parse(sentence)\n",
    "\tfor subtree in result.subtrees():\n",
    "\t\tif subtree.label() == 'NP':\n",
    "\t\t\tt = subtree\n",
    "\t\t\tt = ' '.join(word for word, pos in t.leaves())\n",
    "\t\t\tprint(t)\n",
    "\n",
    "\n",
    "\n",
    "sentences = prepareForNLP(\"A prison riot left six members of staff needing hospital treatment earlier this month, the BBC learns\")\n",
    "for sentence in sentences:\n",
    "\tchunk(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('will', 'MD'), ('be', 'VB'), ('chunked', 'VBN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('for', 'IN'), ('Test', 'NNP'), ('.', '.'), ('World', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('.', '.'), ('Hello', 'NNP'), ('world', 'NN'), ('.', '.')]\n",
      "(S\n",
      "  This/DT\n",
      "  will/MD\n",
      "  (chunk be/VB chunked/VBN)\n",
      "  ./.\n",
      "  This/DT\n",
      "  (chunk is/VBZ)\n",
      "  for/IN\n",
      "  (chunk Test/NNP)\n",
      "  ./.\n",
      "  (chunk World/NNP is/VBZ)\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  (chunk Hello/NNP world/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# POS tagging\n",
    "sent = \"This will be chunked. This is for Test. World is awesome. Hello world.\"\n",
    "\n",
    "print(nltk.pos_tag(word_tokenize(sent)))\n",
    "\n",
    "# creating a regular expression for chunking verbs and nouns\n",
    "chunkRule = r\"\"\"chunk: {<NN.?>*<NNS.?>*<NNP.?>*<NNPS.?>*<VB.?>*<VBD.?>*<VBG.?>*<VBN.?>*<VBP.?>*<VBZ.?>*}\"\"\"\n",
    "\n",
    "My_parser = nltk.RegexpParser(chunkRule)\n",
    "chunked = My_parser.parse(nltk.pos_tag(word_tokenize(sent)))\n",
    "\n",
    "print(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ChunkString: '<DT><NN><VBZ><JJ><NNS>'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk.regexp import ChunkString, ChunkRule, ChinkRule\n",
    "from nltk.tree import Tree\n",
    "t = Tree('S', [('the', 'DT'), ('book', 'NN'), ('has', 'VBZ'),('many', 'JJ'), ('chapters', 'NNS')])\n",
    "cs = ChunkString(t)\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ChunkString: '{<DT><NN><VBZ><JJ><NNS>}'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur = ChunkRule('<DT><NN.*><.*>*<NN.*>', 'chunk determiners and nouns')\n",
    "ur.apply(cs)\n",
    "cs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In order to chunk, we combine the part of speech tags with regular expressions. \n",
    "+ = match 1 or more\n",
    "? = match 0 or 1 repetitions.\n",
    "* = match 0 or MORE repetitions\t  \n",
    ". = Any character except a new line\n",
    "\n",
    "<RB.?>*<VB.?>*<NNP>+<NN>?\n",
    "\n",
    "<RB.?>* = \"0 or more of any tense of adverb,\" followed by:\n",
    "<VB.?>* = \"0 or more of any tense of verb,\" followed by:\n",
    "<NNP>+ = \"One or more proper nouns,\" followed by\n",
    "<NN>? = \"zero or one singular noun.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ChunkString: '{<DT><NN>}<VBZ>{<JJ><NNS>}'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = ChinkRule('<VB.*>', 'chink verbs')\n",
    "ir.apply(cs)\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp = chunk.Regexp(\"NP: {<DT>?<JJ>*<NN>}\")\n",
    "#noun phrases that consist of an optional determiner, followed by any number of adjectives, then a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a simple regular expression based NP chunker.\n",
    "import nltk\n",
    "sentence = \"the little yellow dog barked at the cat\"\n",
    "#Define your grammar using regular expressions\n",
    "grammar = ('''\n",
    "    NP: {<DT>?<JJ>*<NN>} # NP\n",
    "    ''')\n",
    "chunkParser = nltk.RegexpParser(grammar)\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n",
      "(NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "(NP the/DT cat/NN)\n"
     ]
    }
   ],
   "source": [
    "tree = chunkParser.parse(tagged)\n",
    "for subtree in tree.subtrees():\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('will', 'MD'), ('be', 'VB'), ('chunked', 'VBN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('for', 'IN'), ('Test', 'NNP'), ('.', '.'), ('World', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('.', '.'), ('Hello', 'NNP'), ('world', 'NN'), ('.', '.')]\n",
      "(S\n",
      "  This/DT\n",
      "  will/MD\n",
      "  (chunk be/VB chunked/VBN)\n",
      "  ./.\n",
      "  This/DT\n",
      "  (chunk is/VBZ)\n",
      "  for/IN\n",
      "  (chunk Test/NNP)\n",
      "  ./.\n",
      "  (chunk World/NNP is/VBZ)\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  (chunk Hello/NNP world/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
