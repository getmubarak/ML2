{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model:\n",
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "def catdog():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding='same', input_shape=train.shape[1:], activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"First layer...\")\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"Second layer...\")\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    #print(\"Third layer...\")\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #print(\"Flattening, etc...\")\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Creating model:\")\n",
    "model = catdog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "TRAIN_DIR = 'data/image/animal/train2/'\n",
    "TEST_DIR = 'data/image/animal/test2/'\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] \n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "random.shuffle(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds/lib/python3.4/site-packages/matplotlib/__init__.py:892: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5f8bf58908>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEDCAYAAAAx/aOOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nccCXvMefAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f8c1ae438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "def getLabels(list_of_images):\n",
    "    labels = []\n",
    "    \n",
    "    for i in list_of_images:      \n",
    "        if 'dog' in i:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels\n",
    "\n",
    "train_labels = getLabels(train_images)\n",
    "test_labels= getLabels(test_images)\n",
    "sns.countplot(train_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "#We resize our image  to fixed spatial dimensions to ensure each and every image in the input dataset has the same \n",
    "#feature vector‚Äù size. Each image must be represented by a vector.\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    b,g,r = cv2.split(img)\n",
    "    img2 = cv2.merge([r,g,b])\n",
    "    return cv2.resize(img2, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def prepare_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 202\n",
      "Processed 0 of 100\n",
      "Train shape: (202, 3, 64, 64)\n",
      "Test shape: (100, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = prepare_data(train_images)\n",
    "test = prepare_data(test_images)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151 samples, validate on 51 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 2.5509 - acc: 0.4901 - val_loss: 0.7114 - val_acc: 0.4902\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')        \n",
    "       \n",
    "\n",
    "history = LossHistory()\n",
    "        \n",
    "model.fit(train, train_labels, batch_size=batch_size, epochs=epochs,\n",
    "              validation_split=0.25, verbose=2, shuffle=True, callbacks=[history, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
