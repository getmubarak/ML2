{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In general, features can be numerical (e.g. price, length, width, etc…) or categorical (e.g. color, size, etc..). Categorical features are further split into nominal and ordinal features.\n",
    "\n",
    "Ordinal features can be sorted and ordered. For example, size (small, medium, large), we can order these sizes large > medium > small. While nominal features do not have an order for example, color, it doesn’t make any sense to say that red is larger than blue.\n",
    "\n",
    "Most machine learning algorithm require that you convert categorical features into numerical values. One solution would to assign each value a different number starting from zero. (e.g. small à 0 ,medium à 1 ,large à 2)\n",
    "\n",
    "This works well for ordinal features but might cause problems with nominal features (e.g. blue à 0, white à 1, yellow à 2) because even though colors are not ordered the learning algorithm will assume that white is larger than blue and yellow is larger than white and this is not correct.\n",
    "\n",
    "To get around this problem is to use one-hot encoding, the idea is to create a new feature for each unique value of the nominal feature.\n",
    "\n",
    "# COlor          #   Red  Blue  Green\n",
    "1 Red            1   1    0      0\n",
    "2 Blue           2   0    1      0\n",
    "3 Green          3   0    0      0\n",
    "\n",
    "One-Hot Encoding\n",
    "One-Hot Encoding transforms each categorical feature with n possible values into n binary features, with only one active.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "instances = [{'city': 'New York'},{'city': 'San Francisco'},{'city': 'Chapel Hill'}]\n",
    "\n",
    "onehot_encoder = DictVectorizer()\n",
    "onehot_encoder.fit_transform(instances).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 0 1 0 0 1]\n",
      " [0 1 1 1 0 1 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 0]]\n",
      "{'in': 4, 'unc': 9, 'played': 6, 'sandwich': 7, 'basketball': 1, 'lost': 5, 'duke': 2, 'game': 3, 'ate': 0, 'the': 8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['UNC played Duke in basketball',\n",
    "        'Duke lost the basketball game','I ate a sandwich']\n",
    "vectorizer = CountVectorizer()\n",
    "print (vectorizer.fit_transform(corpus).todense())\n",
    "print (vectorizer.vocabulary_)\n",
    "\n",
    "#The  rst word in the dictionary is UNC, so the  rst element in the vector is equal to one. The last word in the\n",
    "#dictionary is game. The  rst document does not contain the word game, so the eighth element in its vector is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
